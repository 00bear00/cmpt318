{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">CMPT318 PROJECT</font>\n",
    "MEMBER:\n",
    "- JEFF\n",
    "- KELVIN\n",
    "- JACKY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from skimage.io import imread_collection\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> I. LOAD THE DATA </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Load Webcam Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_collection = imread_collection('katkam-scaled/*.jpg')\n",
    "images_np = np.array(image_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IMAGE IN NUMPY ARRAY.\n",
    "# images_np\n",
    "# images_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_df = pd.DataFrame(\n",
    "    images_np.reshape(images_np.shape[0],images_np.shape[1] * images_np.shape[2] * images_np.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE IN PANDAS DATAFRAME, AND BEEN RESHAPED.\n",
    "# images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Load Weather Observations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reference: for load multiple file from forder: https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "weather_obv_filenames = glob.glob('yvr-weather/*.csv')\n",
    "weather_obv_df = []\n",
    "\n",
    "for filename in weather_obv_filenames:\n",
    "    weather_obv_df.append(pd.read_csv(filename, skiprows=15)) # first 15 rows are general information, which is not useful data.\n",
    "\n",
    "weather_obv_df = pd.concat(weather_obv_df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEATHER OBSERVATIONS DATAFRAME.\n",
    "# weather_obv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">II. CLEAN&PREPARE DATA</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Clean Webcam Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET IMAGE FILE_NAME\n",
    "image_filenames = np.array(image_collection.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract image shoot date from filename\n",
    "re_image_date = re.compile(r'katkam-\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d')\n",
    "def get_image_time(path):\n",
    "    matches = re_image_date.findall(path)\n",
    "    if matches:\n",
    "        # preocess match learned from https://docs.python.org/2/library/re.html\n",
    "        # take the last match which will be file name\n",
    "        result = matches[-1]\n",
    "        return (int(result[-14:-10]), int(result[-10:-8]), int(result[-8:-6]), result[-6:-4] + ':' + result[-4:-2])\n",
    "    else:\n",
    "        return 'wrong input file name format'\n",
    "get_image_time = np.vectorize(get_image_time)\n",
    "images_date = get_image_time(image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXTRACTED IMAGE DATE\n",
    "# images_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add relevant columns\n",
    "images_df['Year'] = images_date[0]\n",
    "images_df['Month'] = images_date[1]\n",
    "images_df['Day'] = images_date[2]\n",
    "images_df['Time'] = images_date[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE DATA WITH DATE TIME\n",
    "# images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Clean Weather Observations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DROP UNNECESSARY COLUMNS\n",
    "cleaned_weather_obv = weather_obv_df.drop(['index','Data Quality'], axis=1)\n",
    "cleaned_weather_obv = cleaned_weather_obv.drop(['Temp Flag', 'Stn Press Flag','Wind Chill Flag', 'Hmdx Flag', 'Visibility Flag', 'Wind Spd Flag', 'Wind Dir Flag', 'Rel Hum Flag', 'Dew Point Temp Flag'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SPLIT cleaned_weather INTO TWO DATAFRAME, ONE WITH NaN WEATHER COLUMN, ONE WITH NOT NaN COLUMN\n",
    "data_whoseWeather_IsNaN = cleaned_weather_obv[~ cleaned_weather_obv.Weather.notnull()] # weather with Nan\n",
    "main_training_data = cleaned_weather_obv[cleaned_weather_obv.Weather.notnull()] # weather without Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO SPLIT DATAFRAME\n",
    "# data_whoseWeather_IsNaN\n",
    "# main_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_training_data_withoutHW = main_training_data.drop(['Hmdx', 'Wind Chill'],axis=1)\n",
    "final_data = main_training_data_withoutHW.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather description category include\n",
    "- Clear: Clear, Mainly Clear\n",
    "- Cloudy: Cloudy, Mostly Cloudy\t\n",
    "- Fog: Fog, Freezing Fog,\n",
    "- Rain: Drizzle, Freezing Rain, Heavy Rain, Moderate Rain, Moderate Rain Showers, Rain, Rain Showers, Thunderstorms\t\n",
    "- Snow: Moderate Snow, Snow Pellets\t,Ice Pellets, Snow Showers\n",
    "### we decide to use five categories :Clear, Cloudy, Fog, Rain, and Snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHECK THE TOTAL VARIOUS WEATHER DESCRIPTION BEFORE CLEANING\n",
    "# weather_category = final_data.groupby('Weather').count()\n",
    "# weather_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for reduce # of class\n",
    "def removeDuplicate(lst):\n",
    "    lst = lst.split(\",\")\n",
    "#     print(lst)\n",
    "    newlst = \"\"\n",
    "    for i in lst:\n",
    "#         print (i)\n",
    "        if i not in newlst:\n",
    "            newlst = newlst + i + ','\n",
    "    return newlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_clear = re.compile(r'Clear')\n",
    "re_cloudy = re.compile(r'Cloudy')\n",
    "re_fog = re.compile(r'Fog')\n",
    "re_rain = re.compile(r'Rain')\n",
    "re_snow = re.compile(r'Snow')\n",
    "re_drizzle = re.compile(r'Drizzle')\n",
    "re_thunderstorms = re.compile(r'Thunderstorms')\n",
    "re_ice = re.compile(r'Ice')\n",
    "\n",
    "# this output string\n",
    "def clean_weather_description(Str):\n",
    "    result = ''\n",
    "    match_clear = re_clear.search(Str)\n",
    "    if match_clear:\n",
    "        result = result + match_clear[0]+','\n",
    "        \n",
    "    match_cloudy = re_cloudy.search(Str)\n",
    "    if match_cloudy:\n",
    "        result = result + match_cloudy[0]+','\n",
    "        \n",
    "    match_fog = re_fog.search(Str)\n",
    "    if match_fog:\n",
    "        result = result + match_fog[0]+','\n",
    "        \n",
    "    match_rain = re_rain.search(Str)\n",
    "    if match_rain:\n",
    "        result = result + match_rain[0]+','\n",
    "        \n",
    "    match_snow = re_snow.search(Str)\n",
    "    if match_snow:\n",
    "        result = result + match_snow[0]+','\n",
    "        \n",
    "    match_drizzle = re_drizzle.search(Str)\n",
    "    if match_drizzle:\n",
    "        result = result + 'Rain'+','\n",
    "        \n",
    "    match_thunderstorms = re_thunderstorms.search(Str)\n",
    "    if match_thunderstorms:\n",
    "        result = result + 'Rain'+','\n",
    "        \n",
    "    match_ice = re_ice.search(Str)\n",
    "    if match_ice:\n",
    "        result = result + 'Snow'+','\n",
    "    \n",
    "    result = removeDuplicate(result)\n",
    "        \n",
    "    return result[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLEAN THE WEATHER DESCRIPTION CATEGORY\n",
    "final_data['Weather'] =final_data['Weather'].apply(clean_weather_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data[final_data['Weather'] == 'Rain']\n",
    "# SHOW THE NEW WEATHER CATEGORY\n",
    "final_data\n",
    "weather_category = final_data.groupby('Weather').count()\n",
    "weather_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Join Cleaned Webcam Image and Cleaned Weather obserbations Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data = final_data.merge(right = images_df, on = ['Year', 'Month', 'Day', 'Time'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.iloc[:,13:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color=\"blue\"> III. ANALYSE THE DATA </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Use only image to predict weather description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1. <font color=\"black\">Split train_test data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = merged_data.iloc[:,13:]\n",
    "y = merged_data['Weather']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. <font color=\"black\">try Bayesian Classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test)) #within 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "print(stats.normaltest(X_train).pvalue)\n",
    "# p-value too small,so no-normal\n",
    "# don't use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. <font color=\"black\">SVC</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))  #57 0.622103386809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trying different parameter values\n",
    "# model = SVC(kernel='rbf', decision_function_shape='ovr')     #score = 0.397504456328   around 23min\n",
    "# model = SVC(kernel='linear')       # score = 0.668449197861   / 0.620320855615 ///0.641711229947\n",
    "# model = SVC(kernel='rbf', decision_function_shape='ovr')   #score = 0.623885918004\n",
    "model = SVC(kernel='linear', C=1e-1) #41   0.620320855615\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1<font color=\"black\">PCA + SVC</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "model = make_pipeline(\n",
    "    PCA(1000),\n",
    "    SVC(kernel='linear', C=2.0)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))   #0.614973262032/0.620320855615   37-39 2 min fast 18-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adjust C parameter\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "model = make_pipeline(\n",
    "    PCA(1000),\n",
    "    SVC(kernel='linear', C=0.1)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test)) # little bit better 0.625668449198 / 0.6096256684492.run in 03min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adjust PCA parameter\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "model = make_pipeline(\n",
    "    PCA(100),\n",
    "    SVC(kernel='linear', C=2.0)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test)) #02 - 36  very slow, why????? around 35 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adjust PCA parameter\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "model = make_pipeline(\n",
    "    PCA(5000),\n",
    "    SVC(kernel='linear', C=2.0)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test)) #with in 2 min  refine pca   0.654188948307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <font color=\"black\">Nearest Neighbours</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test)) #4 min   0.609625668449 = neighbor5\n",
    "#3.40 min   0.600713012478   meighbors=10         0.616755793226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. <font color=\"black\">neural_network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(), random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))   # 1 min 0.393939393939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(10, 30),\n",
    "                    random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test)) #  5 min 0.399286987522\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Use image and weather conditions to predict weather description\n",
    "Jeff: I think if add weather condition into X, Scaler may need use. Because the unit is much different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. add weather condition to X and split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "X_condition = merged_data.drop(['Weather'], axis=1)\n",
    "X_condition = X_condition.drop(['Time'], axis=1)\n",
    "X_condition = X_condition.drop(['Date/Time','Year','Month','Day'], axis=1)\n",
    "y_condition = merged_data['Weather']\n",
    "X_condition_train, X_condition_test, y_condition_train, y_condition_test = train_test_split(X_condition, y_condition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bayesian classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_condition_train, y_condition_train)\n",
    "print(model.score(X_condition_test, y_condition_test)) #0.549019607843 less than 1 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_condition_train, y_condition_train)\n",
    "print(model.score(X_condition_test, y_condition_test)) #0.668449197861 n=10 5mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <font color=\"black\">SVC try add Scaler, not very different</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline   #with scaler\n",
    "from sklearn.decomposition import PCA\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(5000),\n",
    "    SVC(kernel='linear', C=2.0)\n",
    ")\n",
    "model.fit(X_condition_train, y_condition_train)\n",
    "print(model.score(X_condition_test, y_condition_test))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 SVC <font color=\"black\">Without Scaler</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "best_model = make_pipeline(\n",
    "    PCA(5000),\n",
    "    SVC(kernel='linear', C=2.0)\n",
    ")\n",
    "best_model.fit(X_condition_train, y_condition_train)\n",
    "print(best_model.score(X_condition_test, y_condition_test))   \n",
    "#0.704    this is the best accuracy we can get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. <font color=\"black\">try to deal with multilabel</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"black\">method 1): only use first weather in the weather column. eg: 'Rain,Fog' becomes 'Rain'. The result did not change too much.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cleanMultiLabel(inputstr):\n",
    "#     lst = inputstr.split(\",\")\n",
    "#     if len(lst) > 1:\n",
    "#         return lst[0]\n",
    "#     return inputstr\n",
    "# y_condition = merged_data['Weather'].apply(cleanMultiLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_condition   #there only one weather description in  'Weather' column.\n",
    "# X_condition_train, X_condition_test, y_condition_train, y_condition_test = train_test_split(X_condition, y_condition)\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# model = make_pipeline(\n",
    "#     PCA(5000),\n",
    "#     SVC(kernel='linear', C=2.0)\n",
    "# )\n",
    "# model.fit(X_condition_train, y_condition_train)\n",
    "# print(model.score(X_condition_test, y_condition_test))   \n",
    "# #0.704  //////////////////////not very different to the one without clean multilable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"black\"> method 2 :using multilabelbinarizer </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change the type of Weather column\n",
    "def change_str_to_array(s):\n",
    "    return s.split(',')\n",
    "# change y_train and y_test into proper shape\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y_condition = MultiLabelBinarizer().fit_transform(merged_data['Weather'].apply(change_str_to_array))\n",
    "X_condition_train, X_condition_test, y_condition_train, y_condition_test = train_test_split(X_condition, y_condition)\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "model = make_pipeline(\n",
    "    PCA(5000),\n",
    "    OneVsRestClassifier(SVC(kernel='linear', C=2.0))\n",
    ")\n",
    "model.fit(X_condition_train, y_condition_train)\n",
    "print(model.score(X_condition_test, y_condition_test))  #57% with multilable, <<70.4. maybe because most row are single lablled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> IV. PRESENT RESULT </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"black\">using our best model,find what are the wrong predictions, and analy it to figure out why these predictions are wrong</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "comparsion = pd.DataFrame({'truth': y_condition_test, 'prediction': best_model.predict(X_condition_test)})\n",
    "result = merged_data.join(comparsion, how='outer')\n",
    "result = result.dropna()\n",
    "comparsion_with_date = result[['Date/Time','Time','prediction','truth']]\n",
    "# comparsion_with_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) how many wrong prediction are there  for each hour of the day? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "difference = comparsion_with_date[comparsion_with_date['truth'] != comparsion_with_date['prediction']]\n",
    "print(difference.groupby('Time').count())\n",
    "print(merged_data.groupby('Time').count())\n",
    "# no significant result. altough more wrong predictions in 7am ,10am,etc. The reason is # of points are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) beyond the above question, what is the percentages of wrong predictions in each hour of the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_wrong_prediction = difference.groupby('Time').count() / comparsion_with_date.groupby('Time').count()\n",
    "# highest percentage (most wrong predictions) for 6am maybe because before sun raise, hard to tell if its fog, rain, etc. low percentage (least wrong prediction) for 8 pm, 9 pm seems best but maybe we do not have enough data points at 8 pm and 9pm (because NA for weather column and we dropped it). 11am seems very good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color=\"blue\"> V. Other Interesting RESULT </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### i. Using image to predict time of the day, running the following code may cost about 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate training set and test set\n",
    "X = images_df.iloc[:,:-4]\n",
    "y = images_df['Time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trying to use SVC model \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))  # 0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to use SVC model with PCA\n",
    "model = make_pipeline(\n",
    "    PCA(5000),\n",
    "    SVC(kernel='linear', C=2.0)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))   \n",
    "# 0.5048. Better than Plain SVC.About half can be perdicated correctly. because things like 10am,11am probably looks very similar on the pictures, so it's hard to distinguish them "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
