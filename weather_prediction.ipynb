{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">CMPT318 PROJECT</font>\n",
    "MEMBER:\n",
    "- JEFF\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from skimage.io import imread_collection\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> I. LOAD THE DATA </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Load Webcam Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_collection = imread_collection('katkam-scaled/*.jpg')\n",
    "images_np = np.array(image_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMAGE IN NUMPY ARRAY.\n",
    "# images_np\n",
    "# images_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_df = pd.DataFrame(\n",
    "    images_np.reshape(images_np.shape[0],images_np.shape[1] * images_np.shape[2] * images_np.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMAGE IN PANDAS DATAFRAME, AND BEEN RESHAPED.\n",
    "# images_df\n",
    "# images_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Load Weather Observations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reference: for load multiple file from forder: https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "weather_obv_filenames = glob.glob('yvr-weather/*.csv')\n",
    "weather_obv_df = []\n",
    "\n",
    "for filename in weather_obv_filenames:\n",
    "    weather_obv_df.append(pd.read_csv(filename, skiprows=15)) # first 15 rows are general information, which is not useful data.\n",
    "\n",
    "weather_obv_df = pd.concat(weather_obv_df).reset_index()\n",
    "# pd.read_csv('weather-51442-201607.csv', skiprows=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WEATHER OBSERVATIONS DATAFRAME.\n",
    "# weather_obv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">II. CLEAN&PREPARE DATA</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Clean Webcam Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET IMAGE FILE_NAME\n",
    "image_filenames = np.array(image_collection.files)\n",
    "# image_filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract image shoot date form filename\n",
    "re_image_date = re.compile(r'katkam-\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d')\n",
    "def get_image_time(path):\n",
    "    matches = re_image_date.findall(path)\n",
    "    if matches:\n",
    "        # preocess match learned from https://docs.python.org/2/library/re.html\n",
    "        # take the last match which will be file name\n",
    "        result = matches[-1]\n",
    "        return (int(result[-14:-10]), int(result[-10:-8]), int(result[-8:-6]), result[-6:-4] + ':' + result[-4:-2])\n",
    "    else:\n",
    "        return \"wrong input file name format\"\n",
    "get_image_time = np.vectorize(get_image_time)\n",
    "images_date = get_image_time(image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXTRACTED IMAGE DATE\n",
    "# images_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add relevant columns\n",
    "images_df['Year'] = images_date[0]\n",
    "images_df['Month'] = images_date[1]\n",
    "images_df['Day'] = images_date[2]\n",
    "images_df['Time'] = images_date[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMAGE DATA WITH DATE TIME\n",
    "# images_df['Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Clean Weather Observations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DROP UNCESSARY COLUMNS\n",
    "cleaned_weather_obv = weather_obv_df.drop(['index','Data Quality'], axis=1)\n",
    "cleaned_weather_obv = cleaned_weather_obv.drop(['Temp Flag', 'Stn Press Flag','Wind Chill Flag', 'Hmdx Flag', 'Visibility Flag', 'Wind Spd Flag', 'Wind Dir Flag', 'Rel Hum Flag', 'Dew Point Temp Flag'], axis=1)\n",
    "\n",
    "# type(weather_obv_df['Year'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SPLIT cleaned_weather INTO TWO DATAFRAME, ONE WITH NaN WEATHER COLUMN, ONE WITH NOT NaN COLUMN\n",
    "data_whoseWeather_IsNaN = cleaned_weather_obv[~ cleaned_weather_obv.Weather.notnull()] # weather with Nan\n",
    "main_training_data = cleaned_weather_obv[cleaned_weather_obv.Weather.notnull()] # weather without Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TWO SPLIT DATAFRAME\n",
    "# data_whoseWeather_IsNaN\n",
    "# main_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_training_data_withoutHW = main_training_data.drop(['Hmdx', 'Wind Chill'],axis=1)\n",
    "final_data = main_training_data_withoutHW.dropna().copy()\n",
    "# main_training_data = cleaned_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather description category include\n",
    "- Clear: Clear, Mainly Clear\n",
    "- Cloudy: Cloudy, Mostly Cloudy\t\n",
    "- Fog: Fog, Freezing Fog,\n",
    "- Rain: Drizzle, Freezing Rain, Heavy Rain, Moderate Rain, Moderate Rain Showers, Rain, Rain Showers, Thunderstorms\t\n",
    "- Snow: Moderate Snow, Snow Pellets\t,Ice Pellets, Snow Showers\n",
    "\n",
    "<font color=red>Jacky留言：可以回头讨论 要怎么分类， 我暂时分成不止这5类， 回头商讨商讨</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLEAN HUMAN-GENERATED WEATHER DESCRIPTION\n",
    "# SEE THE TOTAL VARIOUS WEATHER DESCRIPTION USE GROUPBY\n",
    "# weather_category = final_data.groupby('Weather').count()\n",
    "# weather_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #for reduce class\n",
    "# this output string\n",
    "# def removeDuplicate(lst):\n",
    "#     lst = lst.split(\",\")\n",
    "# #     print(lst)\n",
    "#     newlst = \"\"\n",
    "#     for i in lst:\n",
    "# #         print (i)\n",
    "#         if i not in newlst:\n",
    "#             newlst = newlst + i + ','\n",
    "#     return newlst\n",
    "\n",
    "# this output list\n",
    "def removeDuplicate(lst):\n",
    "    lst = lst.split(',')\n",
    "#     print(lst)\n",
    "    newlst = []\n",
    "    for i in lst:\n",
    "#         print (i)\n",
    "        if i not in newlst:\n",
    "            newlst.append(i)\n",
    "    return newlst\n",
    "# removeDuplicate(\"Rain,Clear,Rain,Rain,Fog\") for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re_clear = re.compile(r'Clear')\n",
    "# re_cloudy = re.compile(r'Cloudy')\n",
    "# re_fog = re.compile(r'Fog')\n",
    "# re_rain = re.compile(r'Rain')\n",
    "# re_snow = re.compile(r'Snow')\n",
    "# re_drizzle = re.compile(r'Drizzle')\n",
    "# re_thunderstorms = re.compile(r'Thunderstorms')\n",
    "# re_ice = re.compile(r'Ice')\n",
    "\n",
    "# def clean_weather_description(Str):\n",
    "#     result = ''\n",
    "#     match_clear = re_clear.search(Str)\n",
    "#     if match_clear:\n",
    "#         result = result + match_clear[0]+','\n",
    "        \n",
    "#     match_cloudy = re_cloudy.search(Str)\n",
    "#     if match_cloudy:\n",
    "#         result = result + match_cloudy[0]+','\n",
    "        \n",
    "#     match_fog = re_fog.search(Str)\n",
    "#     if match_fog:\n",
    "#         result = result + match_fog[0]+','\n",
    "        \n",
    "#     match_rain = re_rain.search(Str)\n",
    "#     if match_rain:\n",
    "#         result = result + match_rain[0]+','\n",
    "        \n",
    "#     match_snow = re_snow.search(Str)\n",
    "#     if match_snow:\n",
    "#         result = result + match_snow[0]+','\n",
    "        \n",
    "#     match_drizzle = re_drizzle.search(Str)\n",
    "#     if match_drizzle:\n",
    "#         result = result + match_drizzle[0]+','\n",
    "        \n",
    "#     match_thunderstorms = re_thunderstorms.search(Str)\n",
    "#     if match_thunderstorms:\n",
    "#         result = result + match_thunderstorms[0]+','\n",
    "        \n",
    "#     match_ice = re_ice.search(Str)\n",
    "#     if match_ice:\n",
    "#         result = result + match_ice[0]+','\n",
    "        \n",
    "#     return result[:-1]\n",
    "\n",
    "re_clear = re.compile(r'Clear')\n",
    "re_cloudy = re.compile(r'Cloudy')\n",
    "re_fog = re.compile(r'Fog')\n",
    "re_rain = re.compile(r'Rain')\n",
    "re_snow = re.compile(r'Snow')\n",
    "re_drizzle = re.compile(r'Drizzle')\n",
    "re_thunderstorms = re.compile(r'Thunderstorms')\n",
    "re_ice = re.compile(r'Ice')\n",
    "\n",
    "def clean_weather_description(Str):\n",
    "    result = ''\n",
    "    match_clear = re_clear.search(Str)\n",
    "    if match_clear:\n",
    "        result = result + match_clear[0]+','\n",
    "        \n",
    "    match_cloudy = re_cloudy.search(Str)\n",
    "    if match_cloudy:\n",
    "        result = result + match_cloudy[0]+','\n",
    "        \n",
    "    match_fog = re_fog.search(Str)\n",
    "    if match_fog:\n",
    "        result = result + match_fog[0]+','\n",
    "        \n",
    "    match_rain = re_rain.search(Str)\n",
    "    if match_rain:\n",
    "        result = result + match_rain[0]+','\n",
    "        \n",
    "    match_snow = re_snow.search(Str)\n",
    "    if match_snow:\n",
    "        result = result + match_snow[0]+','\n",
    "        \n",
    "    match_drizzle = re_drizzle.search(Str)\n",
    "    if match_drizzle:\n",
    "        result = result + 'Rain'+','\n",
    "        \n",
    "    match_thunderstorms = re_thunderstorms.search(Str)\n",
    "    if match_thunderstorms:\n",
    "        result = result + 'Rain'+','\n",
    "        \n",
    "    match_ice = re_ice.search(Str)\n",
    "    if match_ice:\n",
    "        result = result + 'Snow'+','\n",
    "    \n",
    "    result = removeDuplicate(result)\n",
    "        \n",
    "    return result[:-1]\n",
    "\n",
    "# clean_weather_description('Thunderstorms,Rain Showers')#test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLEAN THE WEATHER DESCRIPTION CATEGORY\n",
    "final_data['Weather'] =final_data['Weather'].apply(clean_weather_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final_data[final_data['Weather'] == 'Rain']\n",
    "# SHOW THE NEW WEATHER CATEGORY\n",
    "# final_data\n",
    "# weather_category = final_data.groupby('Weather').count()\n",
    "# weather_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Join Cleaned Webcam Image and Cleaned Weather obserbations Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data = final_data.merge(right = images_df, on = ['Year', 'Month', 'Day', 'Time'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color=\"blue\"> III. ANALYSE THE DATA </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"black\">Split train_test data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = merged_data.iloc[:,13:]\n",
    "y = merged_data['Weather']\n",
    "# bayes_X_train, bayes_X_test, bayes_y_train, bayes_y_test = train_test_split(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"black\">try Bayesian Classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# model = GaussianNB()\n",
    "# # model.fit(bayes_X_train, bayes_y_train)\n",
    "# # print(model.score(bayes_X_test, bayes_y_test))\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test)) #within 1 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# print(stats.normaltest(X_train).pvalue)\n",
    "# # p-value too small no-normal\n",
    "# # don't use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color=\"black\">SVC</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# model = SVC(kernel='linear')\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test))  #57 0.622103386809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = SVC(kernel='rbf', decision_function_shape='ovr')     score = 0.397504456328   around 23min\n",
    "# model = SVC(kernel='linear')        score = 0.668449197861   / 0.620320855615 ///0.641711229947\n",
    "# model = SVC(kernel='rbf', decision_function_shape='ovr')   score = 0.623885918004\n",
    "# e-1 model = SVC(kernel='linear', C=1e-1) 41   0.620320855615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"black\">PCA + SVC</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# model = make_pipeline(\n",
    "#     PCA(1000),\n",
    "#     SVC(kernel='linear', C=2.0)\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test))   #0.614973262032/0.620320855615   37-39 2 min fast 18-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# model = make_pipeline(\n",
    "#     PCA(1000),\n",
    "#     SVC(kernel='linear', C=0.1)\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test)) # little bit better 0.625668449198 / 0.6096256684492.03min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# model = make_pipeline(\n",
    "#     PCA(100),\n",
    "#     SVC(kernel='linear', C=2.0)\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test)) #02 - 36  very slow, why????? around 35 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.decomposition import PCA\n",
    "# model = make_pipeline(\n",
    "#     PCA(5000),\n",
    "#     SVC(kernel='linear', C=2.0)\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test)) #with in 2 min  refine pca   0.654188948307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"black\">Nearest Neighbours</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# model = KNeighborsClassifier(n_neighbors=10)\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test)) #4 min   0.609625668449 = neighbor5\n",
    "# #3.40 min   0.600713012478   meighbors=10         0.616755793226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"black\">Jeff: I think if add weather condition into X, Scaler may need use. Because the unit is much different</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"black\">neural_network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# model = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(), random_state=0)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# print(model.score(X_test, y_test))   # 1 min 0.393939393939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# model = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(10, 30),\n",
    "#                       activation='logistic', random_state=0)\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test)) #  1 min 0.399286987522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> IV. PRESENT RESULT </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
